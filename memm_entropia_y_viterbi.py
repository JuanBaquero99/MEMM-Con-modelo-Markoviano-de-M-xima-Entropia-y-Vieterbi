# -*- coding: utf-8 -*-
"""MEMM Entropia y Viterbi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12D7_ur85YRlaFgJrHWs0BoxH-7GLGzzn
"""

import numpy as np

# Datos de ejemplo: secuencia de observaciones y etiquetas
observaciones = ['Sunny', 'Rainy', 'Sunny', 'Cloudy', 'Sunny', 'Rainy', 'Cloudy']
etiquetas = ['Happy', 'Sad', 'Happy', 'Neutral', 'Happy', 'Sad', 'Neutral']

# Convertir etiquetas a números para procesamiento
etiqueta_dict = { 'Happy': 0, 'Sad': 1, 'Neutral': 2 }
observacion_dict = { 'Sunny': 0, 'Rainy': 1, 'Cloudy': 2 }

X = np.array([observacion_dict[o] for o in observaciones])
y = np.array([etiqueta_dict[e] for e in etiquetas])

from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline

# One-hot encoding de las observaciones
onehot_encoder = OneHotEncoder(sparse=False)
X_encoded = onehot_encoder.fit_transform(X.reshape(-1, 1))

# Entrenar el modelo
modelo = LogisticRegression(max_iter=200)
modelo.fit(X_encoded, y)



def viterbi(observaciones, modelo, onehot_encoder, etiqueta_dict):
    n = len(observaciones)
    m = len(etiqueta_dict)

    # Convertir observaciones a one-hot
    observaciones_encoded = onehot_encoder.transform(np.array(observaciones).reshape(-1, 1))

    # Inicializar la matriz de puntuación y la matriz de rastreo
    score_matrix = np.zeros((n, m))
    path_matrix = np.zeros((n, m), dtype=int)

    # Inicializar la primera columna de la matriz de puntuación
    for i in range(m):
        score_matrix[0, i] = modelo.predict_proba(observaciones_encoded[0].reshape(1, -1))[0, i]

    # Rellenar la matriz de puntuación y la matriz de rastreo
    for t in range(1, n):
        for i in range(m):
            max_score = -np.inf
            max_state = 0
            for j in range(m):
                score = score_matrix[t-1, j] * modelo.predict_proba(observaciones_encoded[t].reshape(1, -1))[0, i]
                if score > max_score:
                    max_score = score
                    max_state = j
            score_matrix[t, i] = max_score
            path_matrix[t, i] = max_state

    # Reconstruir el camino óptimo
    best_path = np.zeros(n, dtype=int)
    best_path[-1] = np.argmax(score_matrix[-1])
    for t in range(n-2, -1, -1):
        best_path[t] = path_matrix[t+1, best_path[t+1]]

    # Convertir la secuencia de etiquetas numéricas a etiquetas originales
    reverse_etiqueta_dict = {v: k for k, v in etiqueta_dict.items()}
    best_path_labels = [reverse_etiqueta_dict[state] for state in best_path]

    return best_path_labels

# Ejemplo de uso
observaciones_test = ['Sunny', 'Sunny', 'Cloudy', 'Rainy', 'Sunny']
X_test = np.array([observacion_dict[o] for o in observaciones_test])
resultado = viterbi(X_test, modelo, onehot_encoder, etiqueta_dict)
print("Secuencia más probable de etiquetas:", resultado)